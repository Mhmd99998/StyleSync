{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install scikit-surprise  # Correct package name\n",
        "!pip install --upgrade numpy  # Ensure numpy compatibility"
      ],
      "metadata": {
        "id": "QH7twrYRWrVZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lGmq06PJWEFl",
        "outputId": "64c2a1d7-79ac-41cf-c2f6-c077e8f32549"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using tuned parameters: {'base_diversity_penalty': 0.38, 'content_weight': 0.72, 'exploration_rate': 0.12}\n",
            "\n",
            "=== PERFORMANCE REPORT ===\n",
            "Users Tested: 100\n",
            "Hit Rate: 54.00%\n",
            "Precision@10: 7.50%\n",
            "Recall@10: 3.46%\n",
            "Catalog Coverage: 39.49%\n",
            "Category Diversity: 0.74/1.0\n",
            "\n",
            "=== SAMPLE RECOMMENDATIONS ===\n",
            "\n",
            "User 433c6a36-1ada-40ea-a8a1-8ed56faba54f recommendations:\n",
            "                          variant_id color size  price\n",
            "22a3a856-63b4-48ba-8864-8e5f4ed425c8  Grey    S  34.99\n",
            "2b9995a3-05b6-41cb-b935-92ede22c2846  Grey   2L  10.99\n",
            "2d1efbb9-7a7a-4ca9-b766-4dcc8fffd32e  Grey   2L  29.99\n",
            "3ba3727a-c4e3-438f-9e17-a5de4981d840  Grey    S  39.99\n",
            "51ed9279-1aec-4bff-af22-74af285a7309 Black   2L  69.99\n",
            "803a6f4b-e30b-41e3-8dbe-a0f4607bb262 Black   2L  15.99\n",
            "b9d12bb9-40d6-4d6f-91f3-8bd49156c99b Black   2L  13.99\n",
            "be06fd03-469f-48d3-b0ba-759238cd79ef  Grey   2L  12.99\n",
            "d3d83d15-8be1-447b-bae5-9bd96bcc7208  Grey  XXL  29.99\n",
            "d56099a4-7de9-4185-85c9-78b95fb11007  Grey   2L  21.99\n",
            "\n",
            "User 865014d0-2c41-4099-831b-918bda466a4d recommendations:\n",
            "                          variant_id color size  price\n",
            "22e3d8e5-a493-497f-9689-290b578514c1  Navy   XL  79.99\n",
            "32c541ad-593b-437f-bca7-f85e683687cd  Navy   48 149.99\n",
            "34f8f1ec-61a5-4d38-90eb-8bf15a6f5f4c Brown   26  64.99\n",
            "392be400-5c12-4f6e-ab36-0465a797d9db Black    6 299.99\n",
            "4e98e1c3-0a21-4725-8f9b-414522a60bea Black    4 299.99\n",
            "8d4345cf-1b6f-49fc-b63c-ef90c0785cbc  Grey   XL  49.99\n",
            "ba8e8f86-2ed2-44c0-af5d-013c43502110 Black    4  59.99\n",
            "d005a8a9-0e11-435b-aeca-957bdac19869  Navy   XL  79.99\n",
            "e776fefa-9cab-4bfa-9fa0-2ad228dbb88a  Navy   48 299.99\n",
            "f60933a2-74d2-424e-98a1-f40b68a638a9 Black   38 299.99\n",
            "\n",
            "User 5a4d3ca5-df67-4b46-a01b-003673d1d420 recommendations:\n",
            "                          variant_id color size  price\n",
            "094a3fdd-cf67-47fc-a83d-996e75010e13 Brown    9  39.99\n",
            "14706e51-73ce-45d9-9a8d-e81a993712d5 Black    S  79.99\n",
            "25283adb-4cca-4204-8c2a-50ddd0b4721f Black    S  29.99\n",
            "6926d361-cf4a-46d9-97d0-37812df05c23 Black    S  29.99\n",
            "7737ca04-2890-4ea9-9eca-413d2e92d334  Navy   29  49.99\n",
            "9a29daa4-ac48-47d6-a182-ca0be94c6127 Black    S  29.99\n",
            "ac975271-a9be-4e15-9a6e-5610a08f97af Black    S  34.99\n",
            "b18c81ef-7b38-40b1-9dc6-790251ec5832 Black    S  29.99\n",
            "d63506b1-ed61-4450-a8c7-3e75f0eb6df8 Black    S  29.99\n",
            "ef4b0278-3313-4b90-a612-867e1b3909bb Black    S  34.99\n"
          ]
        }
      ],
      "source": [
        "# === 2. IMPORTS ===\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from collections import defaultdict\n",
        "from sklearn.preprocessing import OneHotEncoder, MinMaxScaler\n",
        "from sklearn.metrics.pairwise import linear_kernel\n",
        "from surprise import SVD, Dataset, Reader\n",
        "from surprise.model_selection import train_test_split\n",
        "from sklearn.model_selection import ParameterGrid\n",
        "import joblib\n",
        "from datetime import datetime\n",
        "\n",
        "# === 3. DATA LOADING & PREPROCESSING ===\n",
        "# Load all datasets\n",
        "products = pd.read_csv('products.csv')\n",
        "variants = pd.read_csv('variants.csv')\n",
        "orders = pd.read_csv('orders.csv')\n",
        "order_items = pd.read_csv('order_items.csv')\n",
        "cart_events = pd.read_csv('cart_events.csv')\n",
        "product_categories = pd.read_csv('product_categories.csv')\n",
        "\n",
        "# Convert date columns\n",
        "orders['created_at'] = pd.to_datetime(orders['created_at'])\n",
        "cart_events['created_at'] = pd.to_datetime(cart_events['created_at'])\n",
        "\n",
        "# Merge product data\n",
        "product_variants = pd.merge(\n",
        "    pd.merge(products, variants, on='product_id'),\n",
        "    product_categories,\n",
        "    on='product_id'\n",
        ").groupby('variant_id').agg({\n",
        "    'color': 'first',\n",
        "    'size': 'first',\n",
        "    'price': 'first',\n",
        "    'stock': 'first',\n",
        "    'category_id': lambda x: list(x.unique())\n",
        "}).reset_index()\n",
        "\n",
        "# Create user interaction datasets\n",
        "user_purchases = pd.merge(\n",
        "    pd.merge(orders, order_items, on='order_id'),\n",
        "    product_variants,\n",
        "    on='variant_id'\n",
        ")\n",
        "\n",
        "user_carts = pd.merge(\n",
        "    cart_events,\n",
        "    product_variants,\n",
        "    on='variant_id'\n",
        ")\n",
        "\n",
        "# === 4. GLOBAL FEATURE ENGINEERING ===\n",
        "encoder = OneHotEncoder(sparse_output=False, handle_unknown='ignore')\n",
        "encoder.fit(product_variants[['color', 'size']])\n",
        "\n",
        "scaler = MinMaxScaler()\n",
        "scaler.fit(product_variants[['price']])\n",
        "\n",
        "# Create feature matrix\n",
        "categorical_features = encoder.transform(product_variants[['color', 'size']])\n",
        "numerical_features = scaler.transform(product_variants[['price']])\n",
        "feature_matrix = np.hstack([categorical_features, numerical_features])\n",
        "\n",
        "# === 5. CONTENT-BASED COMPONENTS (UPDATED) ===\n",
        "def create_user_profile(user_id):\n",
        "    \"\"\"Create temporal-aware user profile\"\"\"\n",
        "    purchased = user_purchases[user_purchases['user_id'] == user_id].copy()\n",
        "    carted = user_carts[user_carts['user_id'] == user_id].copy()\n",
        "\n",
        "    if purchased.empty and carted.empty:\n",
        "        return np.zeros(feature_matrix.shape[1])\n",
        "\n",
        "    # Temporal weighting\n",
        "    current_date = datetime.now()\n",
        "\n",
        "    # Purchase recency (14-day half-life)\n",
        "    purchased['days_ago'] = (current_date - purchased['created_at']).dt.days\n",
        "    purchased_weights = np.exp(-purchased['days_ago']/14)\n",
        "\n",
        "    # Cart recency (7-day half-life)\n",
        "    carted['days_ago'] = (current_date - carted['created_at']).dt.days\n",
        "    carted_weights = 0.7 * np.exp(-carted['days_ago']/7)\n",
        "\n",
        "    interactions = pd.concat([purchased, carted])\n",
        "    weights = np.concatenate([purchased_weights, carted_weights])\n",
        "\n",
        "    # Transform features\n",
        "    categorical = encoder.transform(interactions[['color', 'size']])\n",
        "    numerical = scaler.transform(interactions[['price']])\n",
        "    features = np.hstack([categorical, numerical])\n",
        "\n",
        "    return np.average(features, axis=0, weights=weights)\n",
        "\n",
        "def recommend_content(user_profile, n=50):\n",
        "    \"\"\"Content-based recommendations using linear kernel\"\"\"\n",
        "    if np.all(user_profile == 0):\n",
        "        return []\n",
        "\n",
        "    similarities = linear_kernel([user_profile], feature_matrix)[0]\n",
        "    return product_variants.iloc[np.argsort(similarities)[::-1][:n]]['variant_id'].tolist()\n",
        "\n",
        "# === 6. COLLABORATIVE FILTERING (ENHANCED) ===\n",
        "reader = Reader(rating_scale=(0, 5))\n",
        "data = Dataset.load_from_df(\n",
        "    user_purchases[['user_id', 'variant_id', 'quantity']],\n",
        "    reader\n",
        ")\n",
        "\n",
        "trainset, testset = train_test_split(data, test_size=0.25)\n",
        "algo = SVD(\n",
        "    n_factors=100,\n",
        "    n_epochs=30,\n",
        "    lr_all=0.007,\n",
        "    reg_all=0.1,\n",
        "    random_state=42\n",
        ")\n",
        "algo.fit(trainset)\n",
        "\n",
        "def recommend_collab(user_id, n=50):\n",
        "    \"\"\"Collaborative filtering recommendations with fallback\"\"\"\n",
        "    try:\n",
        "        testset = [[user_id, variant, 0] for variant in product_variants['variant_id']]\n",
        "        predictions = algo.test(testset)\n",
        "        return [pred.iid for pred in sorted(predictions, key=lambda x: x.est, reverse=True)[:n]]\n",
        "    except Exception as e:\n",
        "        return []\n",
        "\n",
        "# === 7. HYBRID RECOMMENDATION SYSTEM (FINAL) ===\n",
        "def hybrid_recommendation(user_id,\n",
        "                         content_weight=0.6,\n",
        "                         collab_weight=0.25,\n",
        "                         base_diversity_penalty=0.4,\n",
        "                         novelty_strength=0.35,\n",
        "                         exploration_rate=0.15,\n",
        "                         size_penalty=0.2,\n",
        "                         color_penalty=0.3):\n",
        "    \"\"\"Enhanced hybrid recommendations with multi-factor diversity\"\"\"\n",
        "    # Get user data\n",
        "    user_history = user_purchases[user_purchases['user_id'] == user_id]\n",
        "    user_cart_history = user_carts[user_carts['user_id'] == user_id]\n",
        "\n",
        "    # ===== 1. COLD-START HANDLING =====\n",
        "    if len(user_history) < 3:\n",
        "        # Use cart data for better cold-start\n",
        "        cart_cats = user_cart_history['category_id'].explode().unique()\n",
        "        user_cats = list(user_history['category_id'].explode().unique()) + list(cart_cats)\n",
        "        user_price = user_history['price'].mean() if not user_history.empty else None\n",
        "\n",
        "        # Price-aware cold-start\n",
        "        price_filter = product_variants['price'] <= (user_price * 1.5 if user_price else 100)\n",
        "        relevant_items = product_variants[\n",
        "            (product_variants['category_id'].apply(lambda x: any(c in user_cats for c in x))) &\n",
        "            price_filter\n",
        "        ]\n",
        "\n",
        "        return list(set(\n",
        "            user_purchases['variant_id'].value_counts().head(5).index.tolist() +\n",
        "            relevant_items.sample(5)['variant_id'].tolist()\n",
        "        ))[:10]\n",
        "\n",
        "    # ===== 2. USER CONTEXT =====\n",
        "    profile = create_user_profile(user_id)\n",
        "    content_recs = recommend_content(profile)\n",
        "    collab_recs = recommend_collab(user_id)\n",
        "\n",
        "    # Calculate user's price tier\n",
        "    user_avg_price = user_history['price'].mean()\n",
        "    price_tiers = [\n",
        "        (0, 50),\n",
        "        (50, 150),\n",
        "        (150, float('inf'))\n",
        "    ]\n",
        "    user_tier = next(i for i, (low, high) in enumerate(price_tiers) if low <= user_avg_price < high)\n",
        "\n",
        "    # ===== 3. SCORING WITH ENHANCED DIVERSITY =====\n",
        "    variant_data = product_variants.set_index('variant_id')\n",
        "    scores = defaultdict(float)\n",
        "    seen_categories = set()\n",
        "    seen_sizes = set()\n",
        "    seen_colors = set()\n",
        "\n",
        "    # Process content recommendations\n",
        "    for i, variant in enumerate(content_recs):\n",
        "        # Adaptive diversity penalties\n",
        "        diversity_penalty = min(\n",
        "            base_diversity_penalty * (i/len(content_recs)),\n",
        "            0.6  # Max penalty\n",
        "        )\n",
        "\n",
        "        categories = variant_data.loc[variant, 'category_id']\n",
        "        price = variant_data.loc[variant, 'price']\n",
        "        size = variant_data.loc[variant, 'size']\n",
        "        color = variant_data.loc[variant, 'color']\n",
        "\n",
        "        score = (len(content_recs) - i) * content_weight\n",
        "\n",
        "        # Apply diversity penalties\n",
        "        if any(c in seen_categories for c in categories):\n",
        "            score *= (1 - diversity_penalty)\n",
        "        if size in seen_sizes:\n",
        "            score *= (1 - size_penalty)\n",
        "        if color in seen_colors:\n",
        "            score *= (1 - color_penalty)\n",
        "\n",
        "        # Price tier penalty\n",
        "        variant_tier = next(i for i, (low, high) in enumerate(price_tiers) if low <= price < high)\n",
        "        if variant_tier != user_tier:\n",
        "            score *= 0.7\n",
        "\n",
        "        # Novelty boost\n",
        "        popularity = user_purchases['variant_id'].value_counts(normalize=True).get(variant, 0)\n",
        "        score *= (1 + (1 - popularity) * novelty_strength)\n",
        "\n",
        "        scores[variant] += score\n",
        "        seen_categories.update(categories)\n",
        "        seen_sizes.add(size)\n",
        "        seen_colors.add(color)\n",
        "\n",
        "    # Process collaborative recommendations\n",
        "    seen_categories = set()\n",
        "    seen_sizes = set()\n",
        "    seen_colors = set()\n",
        "\n",
        "    for i, variant in enumerate(collab_recs):\n",
        "        diversity_penalty = min(\n",
        "            base_diversity_penalty * (i/len(collab_recs)),\n",
        "            0.6\n",
        "        )\n",
        "\n",
        "        categories = variant_data.loc[variant, 'category_id']\n",
        "        price = variant_data.loc[variant, 'price']\n",
        "        size = variant_data.loc[variant, 'size']\n",
        "        color = variant_data.loc[variant, 'color']\n",
        "\n",
        "        score = (len(collab_recs) - i) * collab_weight\n",
        "\n",
        "        if any(c in seen_categories for c in categories):\n",
        "            score *= (1 - diversity_penalty)\n",
        "        if size in seen_sizes:\n",
        "            score *= (1 - size_penalty)\n",
        "        if color in seen_colors:\n",
        "            score *= (1 - color_penalty)\n",
        "\n",
        "        variant_tier = next(i for i, (low, high) in enumerate(price_tiers) if low <= price < high)\n",
        "        if variant_tier != user_tier:\n",
        "            score *= 0.7\n",
        "\n",
        "        popularity = user_purchases['variant_id'].value_counts(normalize=True).get(variant, 0)\n",
        "        score *= (1 + (1 - popularity) * novelty_strength)\n",
        "\n",
        "        scores[variant] += score\n",
        "        seen_categories.update(categories)\n",
        "        seen_sizes.add(size)\n",
        "        seen_colors.add(color)\n",
        "\n",
        "    # ===== 4. RE-RANKING & EXPLORATION =====\n",
        "    # Get top candidates\n",
        "    candidates = sorted(scores.items(), key=lambda x: x[1], reverse=True)[:25]\n",
        "\n",
        "    # Re-rank with diversity\n",
        "    final_recs = []\n",
        "    seen_cats = set()\n",
        "    seen_sizes = set()\n",
        "    seen_colors = set()\n",
        "\n",
        "    for variant, score in candidates:\n",
        "        cats = variant_data.loc[variant, 'category_id']\n",
        "        size = variant_data.loc[variant, 'size']\n",
        "        color = variant_data.loc[variant, 'color']\n",
        "\n",
        "        diversity_score = (\n",
        "            0.4 * len(set(cats) - seen_cats) +\n",
        "            0.3 * (size not in seen_sizes) +\n",
        "            0.3 * (color not in seen_colors)\n",
        "        )\n",
        "\n",
        "        final_recs.append((variant, score + diversity_score))\n",
        "\n",
        "    # Sort by combined score\n",
        "    final_recs = sorted(final_recs, key=lambda x: x[1], reverse=True)[:8]\n",
        "    final_recs = [v[0] for v in final_recs]\n",
        "\n",
        "    # Add exploration\n",
        "    exploration_candidates = product_variants[\n",
        "        (product_variants['stock'] > 0) &\n",
        "        (product_variants['price'].between(user_avg_price*0.8, user_avg_price*1.2))\n",
        "    ].sample(frac=0.1)\n",
        "\n",
        "    if not exploration_candidates.empty:\n",
        "        exploration_items = exploration_candidates['variant_id'].tolist()[:2]\n",
        "        final_recs += exploration_items\n",
        "\n",
        "    return final_recs[:10]\n",
        "\n",
        "# === 8. HYPERPARAMETER TUNING ===\n",
        "def tune_parameters(test_users, param_grid, num_combinations=50):\n",
        "    \"\"\"Grid search for optimal parameters\"\"\"\n",
        "    best_score = -np.inf\n",
        "    best_params = {}\n",
        "    results = []\n",
        "\n",
        "    # Create smaller grid if needed\n",
        "    grid = list(ParameterGrid(param_grid))[:num_combinations]\n",
        "\n",
        "    for i, params in enumerate(grid):\n",
        "        print(f\"\\nTesting combination {i+1}/{len(grid)}: {params}\")\n",
        "\n",
        "        # Temporary recommendation function with current params\n",
        "        def tuned_recommender(user_id):\n",
        "            return hybrid_recommendation(\n",
        "                user_id,\n",
        "                content_weight=params.get('content_weight', 0.7),\n",
        "                collab_weight=params.get('collab_weight', 0.3),\n",
        "                base_diversity_penalty=params.get('base_diversity_penalty', 0.4),\n",
        "                novelty_strength=params.get('novelty_strength', 0.3),\n",
        "                exploration_rate=params.get('exploration_rate', 0.1)\n",
        "            )\n",
        "\n",
        "        # Evaluate with current parameters\n",
        "        performance = evaluate_recommendations(test_users, recommender=tuned_recommender)\n",
        "\n",
        "        # Calculate composite score (adjust weights as needed)\n",
        "        composite_score = (\n",
        "            0.4 * performance['precision@k'] +\n",
        "            0.3 * performance['recall@k'] +\n",
        "            0.2 * performance['coverage'] +\n",
        "            0.1 * performance['diversity']\n",
        "        )\n",
        "\n",
        "        results.append({\n",
        "            'params': params,\n",
        "            'performance': performance,\n",
        "            'score': composite_score\n",
        "        })\n",
        "\n",
        "        if composite_score > best_score:\n",
        "            best_score = composite_score\n",
        "            best_params = params\n",
        "            print(f\"New best score: {best_score:.3f}\")\n",
        "\n",
        "    # Save results\n",
        "    joblib.dump(results, 'tuning_results.pkl')\n",
        "    joblib.dump(best_params, 'best_params.pkl')\n",
        "\n",
        "    return best_params, results\n",
        "\n",
        "# Define parameter grid\n",
        "param_grid = {\n",
        "    'content_weight': [0.6, 0.7, 0.8],\n",
        "    'collab_weight': [0.2, 0.25, 0.3],\n",
        "    'base_diversity_penalty': [0.3, 0.4, 0.5],\n",
        "    'novelty_strength': [0.25, 0.3, 0.35],\n",
        "    'exploration_rate': [0.1, 0.15, 0.2]\n",
        "}\n",
        "\n",
        "# Get active users for tuning\n",
        "tune_users = user_purchases['user_id'].value_counts().index.tolist()[:200]\n",
        "\n",
        "# === 9. EVALUATION & TESTING ===\n",
        "def evaluate_recommendations(test_users, k=10, recommender=None):\n",
        "    \"\"\"Calculate performance metrics\"\"\"\n",
        "    metrics = {\n",
        "        'hit_rate': 0,\n",
        "        'precision@k': [],\n",
        "        'recall@k': [],\n",
        "        'coverage': set(),\n",
        "        'diversity': []\n",
        "    }\n",
        "\n",
        "    total_variants = product_variants['variant_id'].nunique()\n",
        "\n",
        "    # Use custom recommender if provided\n",
        "    recommend_func = recommender or hybrid_recommendation\n",
        "\n",
        "    for user_id in test_users:\n",
        "        purchased = user_purchases[user_purchases['user_id'] == user_id]['variant_id'].tolist()\n",
        "        if not purchased:\n",
        "            continue\n",
        "\n",
        "        recs = recommend_func(user_id)[:k]\n",
        "        relevant = set(recs) & set(purchased)\n",
        "\n",
        "        # Basic metrics\n",
        "        metrics['hit_rate'] += 1 if relevant else 0\n",
        "        metrics['precision@k'].append(len(relevant)/k)\n",
        "        metrics['recall@k'].append(len(relevant)/len(purchased))\n",
        "\n",
        "        # Coverage\n",
        "        metrics['coverage'].update(recs)\n",
        "\n",
        "        # Diversity\n",
        "        categories = product_variants[product_variants['variant_id'].isin(recs)]['category_id'].explode().nunique()\n",
        "        metrics['diversity'].append(categories/k)\n",
        "\n",
        "    return {\n",
        "        'users_tested': len(test_users),\n",
        "        'hit_rate': metrics['hit_rate']/len(test_users),\n",
        "        'precision@k': np.nanmean(metrics['precision@k']),\n",
        "        'recall@k': np.nanmean(metrics['recall@k']),\n",
        "        'coverage': len(metrics['coverage'])/total_variants,\n",
        "        'diversity': np.nanmean(metrics['diversity'])\n",
        "    }\n",
        "\n",
        "def test_system(use_tuned_params=True):\n",
        "    \"\"\"Run full test and display results\"\"\"\n",
        "    # Load best parameters\n",
        "    if use_tuned_params:\n",
        "        try:\n",
        "            best_params = joblib.load('best_params.pkl')\n",
        "            print(\"Using tuned parameters:\", best_params)\n",
        "        except:\n",
        "            print(\"No tuned parameters found, using defaults\")\n",
        "            best_params = {}\n",
        "    else:\n",
        "        best_params = {}\n",
        "\n",
        "    # Get active users with purchase history\n",
        "    active_users = user_purchases['user_id'].value_counts().index.tolist()[:100]\n",
        "\n",
        "    def tuned_recommender(user_id):\n",
        "      return hybrid_recommendation(\n",
        "          user_id,\n",
        "          **best_params\n",
        "      )\n",
        "\n",
        "    # Run evaluation\n",
        "    performance = evaluate_recommendations(active_users, recommender=tuned_recommender)\n",
        "\n",
        "    # Print metrics\n",
        "    print(\"\\n=== PERFORMANCE REPORT ===\")\n",
        "    print(f\"Users Tested: {performance['users_tested']}\")\n",
        "    print(f\"Hit Rate: {performance['hit_rate']:.2%}\")\n",
        "    print(f\"Precision@10: {performance['precision@k']:.2%}\")\n",
        "    print(f\"Recall@10: {performance['recall@k']:.2%}\")\n",
        "    print(f\"Catalog Coverage: {performance['coverage']:.2%}\")\n",
        "    print(f\"Category Diversity: {performance['diversity']:.2f}/1.0\")\n",
        "\n",
        "    # Show sample recommendations\n",
        "    print(\"\\n=== SAMPLE RECOMMENDATIONS ===\")\n",
        "    for user_id in active_users[:3]:\n",
        "        recs = hybrid_recommendation(user_id)[:10]\n",
        "        details = product_variants[product_variants['variant_id'].isin(recs)][['variant_id', 'color', 'size', 'price']]\n",
        "        print(f\"\\nUser {user_id} recommendations:\")\n",
        "        print(details.to_string(index=False))\n",
        "\n",
        "# === 10. RUN THE TEST ===\n",
        "if __name__ == \"__main__\":\n",
        "    # # 1. Initial quick search\n",
        "    # tune_parameters(tune_users, param_grid, num_combinations=20)\n",
        "\n",
        "    # # 2. Refine grid around promising values\n",
        "    # refined_grid = {\n",
        "    #     'content_weight': [0.68, 0.7, 0.72],\n",
        "    #     'base_diversity_penalty': [0.38, 0.4, 0.42],\n",
        "    #     'exploration_rate': [0.12, 0.15, 0.18]\n",
        "    # }\n",
        "    # tune_parameters(tune_users, refined_grid, num_combinations=30)\n",
        "    test_system(use_tuned_params=True)"
      ]
    }
  ]
}